{
  "audit_date": "2026-02-04T08:47:58.916905+00:00",
  "cheap_mode": true,
  "api_models_available": [
    "babbage-002",
    "chatgpt-4o-latest",
    "chatgpt-image-latest",
    "codex-mini-latest",
    "computer-use-preview",
    "computer-use-preview-2025-03-11",
    "dall-e-2",
    "dall-e-3",
    "davinci-002",
    "gpt-3.5-turbo",
    "gpt-3.5-turbo-0125",
    "gpt-3.5-turbo-1106",
    "gpt-3.5-turbo-16k",
    "gpt-3.5-turbo-instruct",
    "gpt-3.5-turbo-instruct-0914",
    "gpt-4",
    "gpt-4-0125-preview",
    "gpt-4-0613",
    "gpt-4-1106-preview",
    "gpt-4-turbo",
    "gpt-4-turbo-2024-04-09",
    "gpt-4-turbo-preview",
    "gpt-4.1",
    "gpt-4.1-2025-04-14",
    "gpt-4.1-mini",
    "gpt-4.1-mini-2025-04-14",
    "gpt-4.1-nano",
    "gpt-4.1-nano-2025-04-14",
    "gpt-4o",
    "gpt-4o-2024-05-13",
    "gpt-4o-2024-08-06",
    "gpt-4o-2024-11-20",
    "gpt-4o-audio-preview",
    "gpt-4o-audio-preview-2024-12-17",
    "gpt-4o-audio-preview-2025-06-03",
    "gpt-4o-mini",
    "gpt-4o-mini-2024-07-18",
    "gpt-4o-mini-audio-preview",
    "gpt-4o-mini-audio-preview-2024-12-17",
    "gpt-4o-mini-realtime-preview",
    "gpt-4o-mini-realtime-preview-2024-12-17",
    "gpt-4o-mini-search-preview",
    "gpt-4o-mini-search-preview-2025-03-11",
    "gpt-4o-mini-transcribe",
    "gpt-4o-mini-transcribe-2025-03-20",
    "gpt-4o-mini-transcribe-2025-12-15",
    "gpt-4o-mini-tts",
    "gpt-4o-mini-tts-2025-03-20",
    "gpt-4o-mini-tts-2025-12-15",
    "gpt-4o-realtime-preview",
    "gpt-4o-realtime-preview-2024-12-17",
    "gpt-4o-realtime-preview-2025-06-03",
    "gpt-4o-search-preview",
    "gpt-4o-search-preview-2025-03-11",
    "gpt-4o-transcribe",
    "gpt-4o-transcribe-diarize",
    "gpt-5",
    "gpt-5-2025-08-07",
    "gpt-5-chat-latest",
    "gpt-5-codex",
    "gpt-5-mini",
    "gpt-5-mini-2025-08-07",
    "gpt-5-nano",
    "gpt-5-nano-2025-08-07",
    "gpt-5-pro",
    "gpt-5-pro-2025-10-06",
    "gpt-5-search-api",
    "gpt-5-search-api-2025-10-14",
    "gpt-5.1",
    "gpt-5.1-2025-11-13",
    "gpt-5.1-chat-latest",
    "gpt-5.1-codex",
    "gpt-5.1-codex-max",
    "gpt-5.1-codex-mini",
    "gpt-5.2",
    "gpt-5.2-2025-12-11",
    "gpt-5.2-chat-latest",
    "gpt-5.2-codex",
    "gpt-5.2-pro",
    "gpt-5.2-pro-2025-12-11",
    "gpt-audio",
    "gpt-audio-2025-08-28",
    "gpt-audio-mini",
    "gpt-audio-mini-2025-10-06",
    "gpt-audio-mini-2025-12-15",
    "gpt-image-1",
    "gpt-image-1-mini",
    "gpt-image-1.5",
    "gpt-realtime",
    "gpt-realtime-2025-08-28",
    "gpt-realtime-mini",
    "gpt-realtime-mini-2025-10-06",
    "gpt-realtime-mini-2025-12-15",
    "o1",
    "o1-2024-12-17",
    "o1-pro",
    "o1-pro-2025-03-19",
    "o3",
    "o3-2025-04-16",
    "o3-deep-research",
    "o3-deep-research-2025-06-26",
    "o3-mini",
    "o3-mini-2025-01-31",
    "o3-pro",
    "o3-pro-2025-06-10",
    "o4-mini",
    "o4-mini-2025-04-16",
    "o4-mini-deep-research",
    "o4-mini-deep-research-2025-06-26",
    "omni-moderation-2024-09-26",
    "omni-moderation-latest",
    "sora-2",
    "sora-2-pro",
    "text-embedding-3-large",
    "text-embedding-3-small",
    "text-embedding-ada-002",
    "tts-1",
    "tts-1-1106",
    "tts-1-hd",
    "tts-1-hd-1106",
    "whisper-1"
  ],
  "models_skipped": [
    "babbage-002",
    "codex-mini-latest",
    "computer-use-preview",
    "computer-use-preview-2025-03-11",
    "dall-e-2",
    "dall-e-3",
    "davinci-002",
    "gpt-4o-mini-realtime-preview",
    "gpt-4o-mini-realtime-preview-2024-12-17",
    "gpt-4o-mini-transcribe",
    "gpt-4o-mini-transcribe-2025-03-20",
    "gpt-4o-mini-transcribe-2025-12-15",
    "gpt-4o-mini-tts",
    "gpt-4o-mini-tts-2025-03-20",
    "gpt-4o-mini-tts-2025-12-15",
    "gpt-4o-realtime-preview",
    "gpt-4o-realtime-preview-2024-12-17",
    "gpt-4o-realtime-preview-2025-06-03",
    "gpt-4o-transcribe",
    "gpt-4o-transcribe-diarize",
    "gpt-audio",
    "gpt-audio-2025-08-28",
    "gpt-audio-mini",
    "gpt-audio-mini-2025-10-06",
    "gpt-audio-mini-2025-12-15",
    "gpt-image-1",
    "gpt-image-1-mini",
    "gpt-image-1.5",
    "gpt-realtime",
    "gpt-realtime-2025-08-28",
    "gpt-realtime-mini",
    "gpt-realtime-mini-2025-10-06",
    "gpt-realtime-mini-2025-12-15",
    "omni-moderation-2024-09-26",
    "omni-moderation-latest",
    "sora-2",
    "sora-2-pro",
    "tts-1",
    "tts-1-1106",
    "tts-1-hd",
    "tts-1-hd-1106",
    "whisper-1"
  ],
  "models_probed": {
    "chatgpt-4o-latest": {
      "model_type": "chat",
      "supports_tools": false,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": true,
      "errors": [
        "Error code: 404 - {'error': {'message': 'tools is not supported in this model. For a list of supported models, refer to https://platform.openai.com/docs/guides/function-calling#models-supporting-function-calling.', 'type': 'invalid_request_error', 'param': None, 'code': None}}"
      ]
    },
    "chatgpt-image-latest": {
      "model_type": "unknown",
      "supports_tools": false,
      "supports_streaming": false,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": null,
      "errors": [
        "Error code: 500 - {'error': {'message': 'The server had an error while processing your request. Sorry about that!', 'type': 'server_error', 'param': None, 'code': None}}"
      ]
    },
    "gpt-3.5-turbo": {
      "model_type": "chat",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": true,
      "errors": []
    },
    "gpt-3.5-turbo-0125": {
      "model_type": "chat",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": true,
      "errors": []
    },
    "gpt-3.5-turbo-1106": {
      "model_type": "chat",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": true,
      "errors": []
    },
    "gpt-3.5-turbo-16k": {
      "model_type": "chat",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": true,
      "errors": []
    },
    "gpt-3.5-turbo-instruct": {
      "model_type": "unknown",
      "supports_tools": false,
      "supports_streaming": false,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": null,
      "errors": [
        "Error code: 404 - {'error': {'message': 'This is not a chat model and thus not supported in the v1/chat/completions endpoint. Did you mean to use v1/completions?', 'type': 'invalid_request_error', 'param': 'model', 'code': None}}"
      ]
    },
    "gpt-3.5-turbo-instruct-0914": {
      "model_type": "unknown",
      "supports_tools": false,
      "supports_streaming": false,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": null,
      "errors": [
        "Error code: 404 - {'error': {'message': 'This is not a chat model and thus not supported in the v1/chat/completions endpoint. Did you mean to use v1/completions?', 'type': 'invalid_request_error', 'param': 'model', 'code': None}}"
      ]
    },
    "gpt-4": {
      "model_type": "chat",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": true,
      "errors": []
    },
    "gpt-4-0125-preview": {
      "model_type": "chat",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": true,
      "errors": []
    },
    "gpt-4-0613": {
      "model_type": "chat",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": true,
      "errors": []
    },
    "gpt-4-1106-preview": {
      "model_type": "chat",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": true,
      "errors": []
    },
    "gpt-4-turbo": {
      "model_type": "chat",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": true,
      "errors": []
    },
    "gpt-4-turbo-2024-04-09": {
      "model_type": "chat",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": true,
      "errors": []
    },
    "gpt-4-turbo-preview": {
      "model_type": "chat",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": true,
      "errors": []
    },
    "gpt-4.1": {
      "model_type": "chat",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": true,
      "errors": []
    },
    "gpt-4.1-2025-04-14": {
      "model_type": "chat",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": true,
      "errors": []
    },
    "gpt-4.1-mini": {
      "model_type": "chat",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": true,
      "errors": []
    },
    "gpt-4.1-mini-2025-04-14": {
      "model_type": "chat",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": true,
      "errors": []
    },
    "gpt-4.1-nano": {
      "model_type": "chat",
      "supports_tools": false,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": true,
      "errors": []
    },
    "gpt-4.1-nano-2025-04-14": {
      "model_type": "chat",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": true,
      "errors": []
    },
    "gpt-4o": {
      "model_type": "chat",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": true,
      "errors": []
    },
    "gpt-4o-2024-05-13": {
      "model_type": "chat",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": true,
      "errors": []
    },
    "gpt-4o-2024-08-06": {
      "model_type": "chat",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": true,
      "errors": []
    },
    "gpt-4o-2024-11-20": {
      "model_type": "chat",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": true,
      "errors": []
    },
    "gpt-4o-audio-preview": {
      "model_type": "unknown",
      "supports_tools": false,
      "supports_streaming": false,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": null,
      "errors": [
        "Error code: 400 - {'error': {'message': 'This model requires that either input content or output modality contain audio.', 'type': 'invalid_request_error', 'param': 'model', 'code': 'invalid_value'}}"
      ]
    },
    "gpt-4o-audio-preview-2024-12-17": {
      "model_type": "unknown",
      "supports_tools": false,
      "supports_streaming": false,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": null,
      "errors": [
        "Error code: 400 - {'error': {'message': 'This model requires that either input content or output modality contain audio.', 'type': 'invalid_request_error', 'param': 'model', 'code': 'invalid_value'}}"
      ]
    },
    "gpt-4o-audio-preview-2025-06-03": {
      "model_type": "unknown",
      "supports_tools": false,
      "supports_streaming": false,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": null,
      "errors": [
        "Error code: 400 - {'error': {'message': 'This model requires that either input content or output modality contain audio.', 'type': 'invalid_request_error', 'param': 'model', 'code': 'invalid_value'}}"
      ]
    },
    "gpt-4o-mini": {
      "model_type": "chat",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": true,
      "errors": []
    },
    "gpt-4o-mini-2024-07-18": {
      "model_type": "chat",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": true,
      "errors": []
    },
    "gpt-4o-mini-audio-preview": {
      "model_type": "unknown",
      "supports_tools": false,
      "supports_streaming": false,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": null,
      "errors": [
        "Error code: 400 - {'error': {'message': 'This model requires that either input content or output modality contain audio.', 'type': 'invalid_request_error', 'param': 'model', 'code': 'invalid_value'}}"
      ]
    },
    "gpt-4o-mini-audio-preview-2024-12-17": {
      "model_type": "unknown",
      "supports_tools": false,
      "supports_streaming": false,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": null,
      "errors": [
        "Error code: 400 - {'error': {'message': 'This model requires that either input content or output modality contain audio.', 'type': 'invalid_request_error', 'param': 'model', 'code': 'invalid_value'}}"
      ]
    },
    "gpt-4o-mini-search-preview": {
      "model_type": "chat",
      "supports_tools": false,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": [],
      "uses_max_tokens": true,
      "errors": [
        "Error code: 404 - {'error': {'message': 'tools is not supported in this model. For a list of supported models, refer to https://platform.openai.com/docs/guides/function-calling#models-supporting-function-calling.', 'type': 'invalid_request_error', 'param': None, 'code': None}}",
        "Error code: 429 - {'error': {'message': 'Request too large for gpt-4o-mini-search-preview in organization org-joSSRfzwcCeJwfRDrCenwGqH on input-images per min: Limit 0, Requested 1. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'input-images', 'param': None, 'code': 'rate_limit_exceeded'}}"
      ]
    },
    "gpt-4o-mini-search-preview-2025-03-11": {
      "model_type": "chat",
      "supports_tools": false,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": [],
      "uses_max_tokens": true,
      "errors": [
        "Error code: 404 - {'error': {'message': 'tools is not supported in this model. For a list of supported models, refer to https://platform.openai.com/docs/guides/function-calling#models-supporting-function-calling.', 'type': 'invalid_request_error', 'param': None, 'code': None}}",
        "Error code: 429 - {'error': {'message': 'Request too large for gpt-4o-mini-search-preview in organization org-joSSRfzwcCeJwfRDrCenwGqH on input-images per min: Limit 0, Requested 1. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'input-images', 'param': None, 'code': 'rate_limit_exceeded'}}"
      ]
    },
    "gpt-4o-search-preview": {
      "model_type": "chat",
      "supports_tools": false,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": [],
      "uses_max_tokens": true,
      "errors": [
        "Error code: 404 - {'error': {'message': 'tools is not supported in this model. For a list of supported models, refer to https://platform.openai.com/docs/guides/function-calling#models-supporting-function-calling.', 'type': 'invalid_request_error', 'param': None, 'code': None}}",
        "Error code: 429 - {'error': {'message': 'Request too large for gpt-4o-search-preview in organization org-joSSRfzwcCeJwfRDrCenwGqH on input-images per min: Limit 0, Requested 1. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'input-images', 'param': None, 'code': 'rate_limit_exceeded'}}"
      ]
    },
    "gpt-4o-search-preview-2025-03-11": {
      "model_type": "chat",
      "supports_tools": false,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": [],
      "uses_max_tokens": true,
      "errors": [
        "Error code: 404 - {'error': {'message': 'tools is not supported in this model. For a list of supported models, refer to https://platform.openai.com/docs/guides/function-calling#models-supporting-function-calling.', 'type': 'invalid_request_error', 'param': None, 'code': None}}",
        "Error code: 429 - {'error': {'message': 'Request too large for gpt-4o-search-preview in organization org-joSSRfzwcCeJwfRDrCenwGqH on input-images per min: Limit 0, Requested 1. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'input-images', 'param': None, 'code': 'rate_limit_exceeded'}}"
      ]
    },
    "gpt-5": {
      "model_type": "reasoning",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": [
        1.0
      ],
      "uses_max_tokens": false,
      "errors": []
    },
    "gpt-5-2025-08-07": {
      "model_type": "reasoning",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": [
        1.0
      ],
      "uses_max_tokens": false,
      "errors": []
    },
    "gpt-5-chat-latest": {
      "model_type": "chat",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": true,
      "errors": []
    },
    "gpt-5-mini": {
      "model_type": "reasoning",
      "supports_tools": false,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": [
        1.0
      ],
      "uses_max_tokens": false,
      "errors": [
        "Error code: 400 - {'error': {'message': 'Could not finish the message because max_tokens or model output limit was reached. Please try again with higher max_tokens.', 'type': 'invalid_request_error', 'param': None, 'code': None}}"
      ]
    },
    "gpt-5-mini-2025-08-07": {
      "model_type": "reasoning",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": [
        1.0
      ],
      "uses_max_tokens": false,
      "errors": []
    },
    "gpt-5-nano": {
      "model_type": "reasoning",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": [
        1.0
      ],
      "uses_max_tokens": false,
      "errors": []
    },
    "gpt-5-nano-2025-08-07": {
      "model_type": "reasoning",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": [
        1.0
      ],
      "uses_max_tokens": false,
      "errors": []
    },
    "gpt-5-pro": {
      "model_type": "unknown",
      "supports_tools": false,
      "supports_streaming": false,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": null,
      "errors": [
        "Error code: 404 - {'error': {'message': 'This model is only supported in v1/responses and not in v1/chat/completions.', 'type': 'invalid_request_error', 'param': 'model', 'code': None}}"
      ]
    },
    "gpt-5-pro-2025-10-06": {
      "model_type": "unknown",
      "supports_tools": false,
      "supports_streaming": false,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": null,
      "errors": [
        "Error code: 404 - {'error': {'message': 'This model is only supported in v1/responses and not in v1/chat/completions.', 'type': 'invalid_request_error', 'param': 'model', 'code': None}}"
      ]
    },
    "gpt-5-search-api": {
      "model_type": "chat",
      "supports_tools": false,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": [],
      "uses_max_tokens": true,
      "errors": [
        "Error code: 404 - {'error': {'message': 'tools is not supported in this model. For a list of supported models, refer to https://platform.openai.com/docs/guides/function-calling#models-supporting-function-calling.', 'type': 'invalid_request_error', 'param': None, 'code': None}}"
      ]
    },
    "gpt-5-search-api-2025-10-14": {
      "model_type": "chat",
      "supports_tools": false,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": [],
      "uses_max_tokens": true,
      "errors": [
        "Error code: 404 - {'error': {'message': 'tools is not supported in this model. For a list of supported models, refer to https://platform.openai.com/docs/guides/function-calling#models-supporting-function-calling.', 'type': 'invalid_request_error', 'param': None, 'code': None}}"
      ]
    },
    "gpt-5.1": {
      "model_type": "reasoning",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": false,
      "errors": []
    },
    "gpt-5.1-2025-11-13": {
      "model_type": "reasoning",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": false,
      "errors": []
    },
    "gpt-5.1-chat-latest": {
      "model_type": "reasoning",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": [
        1.0
      ],
      "uses_max_tokens": false,
      "errors": []
    },
    "gpt-5.1-codex": {
      "model_type": "unknown",
      "supports_tools": false,
      "supports_streaming": false,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": null,
      "errors": [
        "Error code: 404 - {'error': {'message': 'This is not a chat model and thus not supported in the v1/chat/completions endpoint. Did you mean to use v1/completions?', 'type': 'invalid_request_error', 'param': 'model', 'code': None}}"
      ]
    },
    "gpt-5.1-codex-max": {
      "model_type": "unknown",
      "supports_tools": false,
      "supports_streaming": false,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": null,
      "errors": [
        "Error code: 404 - {'error': {'message': 'This is not a chat model and thus not supported in the v1/chat/completions endpoint. Did you mean to use v1/completions?', 'type': 'invalid_request_error', 'param': 'model', 'code': None}}"
      ]
    },
    "gpt-5.1-codex-mini": {
      "model_type": "unknown",
      "supports_tools": false,
      "supports_streaming": false,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": null,
      "errors": [
        "Error code: 404 - {'error': {'message': 'This model is only supported in v1/responses and not in v1/chat/completions.', 'type': 'invalid_request_error', 'param': 'model', 'code': None}}"
      ]
    },
    "gpt-5.2": {
      "model_type": "reasoning",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": false,
      "errors": []
    },
    "gpt-5.2-2025-12-11": {
      "model_type": "reasoning",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": false,
      "errors": []
    },
    "gpt-5.2-chat-latest": {
      "model_type": "reasoning",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": [
        1.0
      ],
      "uses_max_tokens": false,
      "errors": []
    },
    "gpt-5.2-codex": {
      "model_type": "unknown",
      "supports_tools": false,
      "supports_streaming": false,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": null,
      "errors": [
        "Error code: 404 - {'error': {'message': 'This is not a chat model and thus not supported in the v1/chat/completions endpoint. Did you mean to use v1/completions?', 'type': 'invalid_request_error', 'param': 'model', 'code': None}}"
      ]
    },
    "gpt-5.2-pro": {
      "model_type": "unknown",
      "supports_tools": false,
      "supports_streaming": false,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": null,
      "errors": [
        "Error code: 404 - {'error': {'message': 'This is not a chat model and thus not supported in the v1/chat/completions endpoint. Did you mean to use v1/completions?', 'type': 'invalid_request_error', 'param': 'model', 'code': None}}"
      ]
    },
    "gpt-5.2-pro-2025-12-11": {
      "model_type": "unknown",
      "supports_tools": false,
      "supports_streaming": false,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": null,
      "errors": [
        "Error code: 404 - {'error': {'message': 'This is not a chat model and thus not supported in the v1/chat/completions endpoint. Did you mean to use v1/completions?', 'type': 'invalid_request_error', 'param': 'model', 'code': None}}"
      ]
    },
    "o1": {
      "model_type": "reasoning",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": [
        1.0
      ],
      "uses_max_tokens": false,
      "errors": []
    },
    "o1-2024-12-17": {
      "model_type": "reasoning",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": [
        1.0
      ],
      "uses_max_tokens": false,
      "errors": []
    },
    "o3": {
      "model_type": "reasoning",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": [
        1.0
      ],
      "uses_max_tokens": false,
      "errors": []
    },
    "o3-2025-04-16": {
      "model_type": "reasoning",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": [
        1.0
      ],
      "uses_max_tokens": false,
      "errors": []
    },
    "o3-mini": {
      "model_type": "reasoning",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": [
        1.0
      ],
      "uses_max_tokens": false,
      "errors": []
    },
    "o3-mini-2025-01-31": {
      "model_type": "reasoning",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": [
        1.0
      ],
      "uses_max_tokens": false,
      "errors": []
    },
    "o4-mini": {
      "model_type": "reasoning",
      "supports_tools": false,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": [
        1.0
      ],
      "uses_max_tokens": false,
      "errors": [
        "Error code: 400 - {'error': {'message': 'Could not finish the message because max_tokens or model output limit was reached. Please try again with higher max_tokens.', 'type': 'invalid_request_error', 'param': None, 'code': None}}"
      ]
    },
    "o4-mini-2025-04-16": {
      "model_type": "reasoning",
      "supports_tools": true,
      "supports_streaming": true,
      "supports_vision": false,
      "supported_temperatures": [
        1.0
      ],
      "uses_max_tokens": false,
      "errors": []
    },
    "text-embedding-3-large": {
      "model_type": "embedding",
      "supports_tools": false,
      "supports_streaming": false,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": null,
      "errors": []
    },
    "text-embedding-3-small": {
      "model_type": "embedding",
      "supports_tools": false,
      "supports_streaming": false,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": null,
      "errors": []
    },
    "text-embedding-ada-002": {
      "model_type": "embedding",
      "supports_tools": false,
      "supports_streaming": false,
      "supports_vision": false,
      "supported_temperatures": null,
      "uses_max_tokens": null,
      "errors": []
    }
  },
  "comparison": {
    "new_models": [
      "chatgpt-image-latest",
      "gpt-5-pro",
      "gpt-5-pro-2025-10-06",
      "gpt-5-search-api",
      "gpt-5-search-api-2025-10-14",
      "gpt-5.1",
      "gpt-5.1-2025-11-13",
      "gpt-5.1-chat-latest",
      "gpt-5.1-codex",
      "gpt-5.1-codex-max",
      "gpt-5.1-codex-mini",
      "gpt-5.2",
      "gpt-5.2-2025-12-11",
      "gpt-5.2-chat-latest",
      "gpt-5.2-codex",
      "gpt-5.2-pro",
      "gpt-5.2-pro-2025-12-11"
    ],
    "removed_models": [
      "gpt-4o-audio-preview-2024-10-01",
      "gpt-4o-mini-realtime-preview",
      "gpt-4o-mini-realtime-preview-2024-12-17",
      "gpt-4o-mini-transcribe",
      "gpt-4o-mini-tts",
      "gpt-4o-realtime-preview",
      "gpt-4o-realtime-preview-2024-10-01",
      "gpt-4o-realtime-preview-2024-12-17",
      "gpt-4o-realtime-preview-2025-06-03",
      "gpt-4o-transcribe",
      "gpt-5-codex",
      "o1-mini",
      "o1-mini-2024-09-12",
      "o1-pro",
      "o1-pro-2025-03-19",
      "o3-deep-research",
      "o3-deep-research-2025-06-26",
      "o3-pro",
      "o3-pro-2025-06-10",
      "o4-mini-deep-research",
      "o4-mini-deep-research-2025-06-26"
    ],
    "capability_changes": {
      "chatgpt-4o-latest": {
        "supports_tools": {
          "was": true,
          "now": false
        },
        "supports_vision": {
          "was": true,
          "now": false
        }
      },
      "gpt-4.1-nano": {
        "supports_tools": {
          "was": true,
          "now": false
        }
      },
      "gpt-4o": {
        "supports_vision": {
          "was": true,
          "now": false
        }
      },
      "gpt-4o-2024-05-13": {
        "supports_vision": {
          "was": true,
          "now": false
        }
      },
      "gpt-4o-2024-08-06": {
        "supports_vision": {
          "was": true,
          "now": false
        }
      },
      "gpt-4o-2024-11-20": {
        "supports_vision": {
          "was": true,
          "now": false
        }
      },
      "gpt-4o-audio-preview": {
        "supports_tools": {
          "was": true,
          "now": false
        },
        "supports_vision": {
          "was": true,
          "now": false
        }
      },
      "gpt-4o-audio-preview-2024-12-17": {
        "supports_tools": {
          "was": true,
          "now": false
        },
        "supports_vision": {
          "was": true,
          "now": false
        }
      },
      "gpt-4o-audio-preview-2025-06-03": {
        "supports_tools": {
          "was": true,
          "now": false
        },
        "supports_vision": {
          "was": true,
          "now": false
        }
      },
      "gpt-4o-mini": {
        "supports_vision": {
          "was": true,
          "now": false
        }
      },
      "gpt-4o-mini-2024-07-18": {
        "supports_vision": {
          "was": true,
          "now": false
        }
      },
      "gpt-4o-mini-audio-preview": {
        "supports_tools": {
          "was": true,
          "now": false
        },
        "supports_vision": {
          "was": true,
          "now": false
        }
      },
      "gpt-4o-mini-audio-preview-2024-12-17": {
        "supports_tools": {
          "was": true,
          "now": false
        },
        "supports_vision": {
          "was": true,
          "now": false
        }
      },
      "gpt-4o-mini-search-preview": {
        "supports_tools": {
          "was": true,
          "now": false
        },
        "supports_vision": {
          "was": true,
          "now": false
        },
        "supported_temperatures": {
          "was": null,
          "now": []
        }
      },
      "gpt-4o-mini-search-preview-2025-03-11": {
        "supports_tools": {
          "was": true,
          "now": false
        },
        "supports_vision": {
          "was": true,
          "now": false
        },
        "supported_temperatures": {
          "was": null,
          "now": []
        }
      },
      "gpt-4o-search-preview": {
        "supports_tools": {
          "was": true,
          "now": false
        },
        "supports_vision": {
          "was": true,
          "now": false
        },
        "supported_temperatures": {
          "was": null,
          "now": []
        }
      },
      "gpt-4o-search-preview-2025-03-11": {
        "supports_tools": {
          "was": true,
          "now": false
        },
        "supports_vision": {
          "was": true,
          "now": false
        },
        "supported_temperatures": {
          "was": null,
          "now": []
        }
      },
      "gpt-5-chat-latest": {
        "model_type": {
          "was": "reasoning",
          "now": "chat"
        },
        "supported_temperatures": {
          "was": [
            1.0
          ],
          "now": null
        }
      },
      "gpt-5-mini": {
        "supports_tools": {
          "was": true,
          "now": false
        }
      },
      "o1": {
        "supports_tools": {
          "was": false,
          "now": true
        },
        "supports_streaming": {
          "was": false,
          "now": true
        }
      },
      "o1-2024-12-17": {
        "supports_tools": {
          "was": false,
          "now": true
        },
        "supports_streaming": {
          "was": false,
          "now": true
        }
      },
      "o3": {
        "supports_tools": {
          "was": false,
          "now": true
        },
        "supports_streaming": {
          "was": false,
          "now": true
        },
        "supported_temperatures": {
          "was": [],
          "now": [
            1.0
          ]
        }
      },
      "o3-2025-04-16": {
        "supports_tools": {
          "was": false,
          "now": true
        },
        "supports_streaming": {
          "was": false,
          "now": true
        },
        "supported_temperatures": {
          "was": [],
          "now": [
            1.0
          ]
        }
      },
      "o3-mini": {
        "supports_tools": {
          "was": false,
          "now": true
        },
        "supports_streaming": {
          "was": false,
          "now": true
        },
        "supported_temperatures": {
          "was": [],
          "now": [
            1.0
          ]
        }
      },
      "o3-mini-2025-01-31": {
        "supports_tools": {
          "was": false,
          "now": true
        },
        "supports_streaming": {
          "was": false,
          "now": true
        },
        "supported_temperatures": {
          "was": [],
          "now": [
            1.0
          ]
        }
      },
      "o4-mini": {
        "supports_streaming": {
          "was": false,
          "now": true
        }
      },
      "o4-mini-2025-04-16": {
        "supports_tools": {
          "was": false,
          "now": true
        },
        "supports_streaming": {
          "was": false,
          "now": true
        }
      }
    }
  }
}